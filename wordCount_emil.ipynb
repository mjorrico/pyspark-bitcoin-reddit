{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ce1b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/10 08:54:33 WARN Utils: Your hostname, HTPC resolves to a loopback address: 127.0.1.1; using 172.25.222.32 instead (on interface eth0)\n",
      "23/03/10 08:54:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/03/10 08:54:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "\n",
    "spark_session = SparkSession.builder\\\n",
    "        .master(\"spark://HTPC.:7077\") \\\n",
    "        .appName(\"Emil_winder\")\\\n",
    "        .config(\"spark.cores.max\", 4)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67370d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# A.1.1\n",
    "spark_context = spark_session.sparkContext\n",
    "df = spark_session.read.json(\"hdfs://localhost:9000/user/emwind/input/sample_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18821688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d16fdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: long (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59857cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                body|\n",
      "+--------------------+\n",
      "|            A quarry|\n",
      "|[Salutations! I'm...|\n",
      "|I got into baseba...|\n",
      "|        FUCKING TORY|\n",
      "|I see a water dra...|\n",
      "|Wait. The Michiga...|\n",
      "|              ye fam|\n",
      "|143417804| &gt; U...|\n",
      "|That is some chic...|\n",
      "|Does he even know...|\n",
      "|            Tequila.|\n",
      "|your heart beats ...|\n",
      "|&gt; Subscribe: /...|\n",
      "|you're really ign...|\n",
      "|lets see how deep...|\n",
      "|You are arguing t...|\n",
      "|I'm thinking abou...|\n",
      "|[Original post](h...|\n",
      "|I think that's a ...|\n",
      "|Harp absolutelly....|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"body\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab88c7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as psf\n",
    "print(df.count())\n",
    "words_list = [\"bitcoin\", \"BTC\",\"cryptocurrency\"]\n",
    "df2 = df.filter(psf.col('body').rlike('(^|\\s)(' + '|'.join(words_list) + ')(\\s|$)')).select(\"body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d732552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "488216c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df2.where(col(\"extracted_word\") != None).select(\"extracted_word\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "116d9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "keywords = [\"bitcoin\", \"btc\", \"cryptocurrency\"]\n",
    "re_pattern = '(' + '|'.join([fr'\\\\b{k}\\\\b' for k in keywords]) + ')'\n",
    "df3 = df.withColumn('matched', F.expr(f\"regexp_extract_all(body, '(?i){re_pattern}', 1)\"))\n",
    "df3 = df3.withColumn('count', F.size('matched'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "82e4c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df4 = df3.filter(col('count') != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a762d20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4d99e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|count|                body|             matched|\n",
      "+-----+--------------------+--------------------+\n",
      "|    3|The title, it is ...|[bitcoin, bitcoin...|\n",
      "|    1|What do you think...|               [btc]|\n",
      "|    2|The problem is th...|  [Bitcoin, Bitcoin]|\n",
      "|    1|Iâ€™m really intere...|    [cryptocurrency]|\n",
      "|    3|I like to diversi...| [BTC, BTC, Bitcoin]|\n",
      "|    1|     Lets bet 1 btc?|               [btc]|\n",
      "|    2|Asicboost does no...|  [bitcoin, bitcoin]|\n",
      "|    1|If we see an esca...|           [Bitcoin]|\n",
      "|    2|I don't see the c...|      [btc, bitcoin]|\n",
      "|    1|Amen. Hoping Bitc...|           [Bitcoin]|\n",
      "|    1|Ok you should rea...|           [bitcoin]|\n",
      "|    1|These people are ...|               [BTC]|\n",
      "|    2|I think it is a s...|  [Bitcoin, Bitcoin]|\n",
      "|    1|I wouldn't call [...|               [BTC]|\n",
      "|    3|So I've been read...|[bitcoin, Bitcoin...|\n",
      "|    1|Here is the post ...|               [BTC]|\n",
      "|    5|u/jessquit, you'v...|[Bitcoin, bitcoin...|\n",
      "|    2|you should use a ...|  [bitcoin, bitcoin]|\n",
      "|    1| [Here is the lin...|           [Bitcoin]|\n",
      "|    1|250 BTC, what a w...|               [BTC]|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df4.select('count', 'body','matched')\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d29e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dff = spark_session.read.json(\"hdfs://localhost:9000/user/emwind/2013-11.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9c4eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = dff.withColumn('matched', F.expr(f\"regexp_extract_all(body, '(?i){re_pattern}', 1)\"))\n",
    "df3 = df3.withColumn('count', F.size('matched'))\n",
    "df5 = df3.filter(col('count') != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58d9c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88858"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "51bbb7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37396497"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad026481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026 0.002376104906296437\n"
     ]
    }
   ],
   "source": [
    "print(26/10000,88858/37396497 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a1345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
